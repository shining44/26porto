1:"$Sreact.fragment"
4:I[22016,["/26porto/_next/static/chunks/5fcf6768c2e01b0d.js"],""]
5:I[97367,["/26porto/_next/static/chunks/ff1a16fafef87110.js","/26porto/_next/static/chunks/7340adf74ff47ec0.js"],"OutletBoundary"]
6:"$Sreact.suspense"
0:{"buildId":"wJmNvrHaXSuk-OdWqoO31","rsc":["$","$1","c",{"children":[["$","div",null,{"className":"max-w-4xl mx-auto px-6 py-24","children":[["$","header",null,{"className":"mb-16","children":[["$","h1",null,{"className":"text-[2.75rem] font-medium tracking-tight mb-4","children":"Research"}],["$","p",null,{"className":"text-lg text-[var(--muted)] max-w-xl","children":"Academic contributions to the field of human-AI interaction design."}]]}],["$","article",null,{"className":"border-t border-[var(--border)] pt-12","children":[["$","div",null,{"className":"mb-8","children":[["$","div",null,{"className":"flex items-center gap-3 mb-4","children":[["$","span",null,{"className":"text-xs text-[var(--muted)] border border-[var(--border)] px-2 py-0.5 rounded","children":"CHI 2024"}],["$","span",null,{"className":"text-xs text-[var(--muted)]","children":"Co-author"}]]}],["$","h2",null,{"className":"text-2xl font-medium tracking-tight mb-3","children":"Design Patterns for Trust Calibration in LLM-Based Conversational Interfaces"}],["$","p",null,{"className":"text-sm text-[var(--muted)] mb-6","children":"Published in Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems"}]]}],["$","section",null,{"className":"mb-12","children":[["$","h3",null,{"className":"text-sm font-medium uppercase tracking-wide text-[var(--muted)] mb-4","children":"Problem"}],["$","p",null,{"className":"text-[var(--muted)]","children":"As large language models become integrated into consumer and enterprise products, users struggle to develop accurate mental models of AI capabilities. This leads to two failure modes: over-trust (accepting incorrect outputs uncritically) and under-trust (failing to use AI for tasks where it excels). The research investigates design interventions that help users calibrate their trust appropriately based on task type, model confidence, and output verifiability."}]]}],["$","section",null,{"className":"mb-12","children":[["$","h3",null,{"className":"text-sm font-medium uppercase tracking-wide text-[var(--muted)] mb-4","children":"Contribution"}],["$","p",null,{"className":"text-[var(--muted)] mb-4","children":"My contribution focused on the design and implementation of interface prototypes used in the study. Working with research partners, I developed a framework of trust calibration patterns that were tested with participants across different experience levels and task domains."}],["$","p",null,{"className":"text-[var(--muted)]","children":"Key design patterns identified include: explicit uncertainty indicators, source attribution hierarchies, comparative response generation, and progressive verification flows. The paper presents empirical evidence for which patterns are most effective in different contexts."}]]}],["$","section",null,{"className":"mb-12","children":[["$","h3",null,{"className":"text-sm font-medium uppercase tracking-wide text-[var(--muted)] mb-4","children":"Outcomes"}],["$","ul",null,{"className":"text-[var(--muted)] list-disc pl-5 space-y-2","children":[["$","li",null,{"children":"The paper was accepted at CHI 2024, the premier venue for human-computer interaction research"}],["$","li",null,{"children":"Findings have been integrated into design guidelines at Meta and influenced industry practices"}],["$","li",null,{"children":"The trust calibration framework is being extended in follow-up research"}]]}]]}],["$","section",null,{"className":"bg-neutral-50 p-6 rounded-lg","children":[["$","h3",null,{"className":"text-sm font-medium uppercase tracking-wide text-[var(--muted)] mb-4","children":"Citation"}],["$","p",null,{"className":"text-sm text-[var(--muted)] font-mono","children":"Chen, L., Tayyebi, A., Ramirez, S., & Wong, K. (2024). Design Patterns for Trust Calibration in LLM-Based Conversational Interfaces. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI '24). ACM, New York, NY, USA."}]]}]]}],"$L2"]}],null,"$L3"]}],"loading":null,"isPartial":false}
2:["$","nav",null,{"className":"pt-12 border-t border-[var(--border)] mt-16","children":["$","$L4",null,{"href":"/about","className":"text-sm text-[var(--muted)] hover:text-[var(--foreground)] transition-colors","children":"Learn more about my background â†’"}]}]
3:["$","$L5",null,{"children":["$","$6",null,{"name":"Next.MetadataOutlet","children":"$@7"}]}]
7:null
