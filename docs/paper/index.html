<!DOCTYPE html><!--wJmNvrHaXSuk_OdWqoO31--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/26porto/_next/static/chunks/91d2d8100e5e5b96.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/26porto/_next/static/chunks/ee072962c21fa1dd.js"/><script src="/26porto/_next/static/chunks/236f7e5abd6f09ff.js" async=""></script><script src="/26porto/_next/static/chunks/cc759f7c2413b7ff.js" async=""></script><script src="/26porto/_next/static/chunks/fca951be71445eb3.js" async=""></script><script src="/26porto/_next/static/chunks/turbopack-1f8920f54ef6ada1.js" async=""></script><script src="/26porto/_next/static/chunks/5fcf6768c2e01b0d.js" async=""></script><script src="/26porto/_next/static/chunks/ff1a16fafef87110.js" async=""></script><script src="/26porto/_next/static/chunks/7340adf74ff47ec0.js" async=""></script><title>Research — Ali Tayyebi</title><meta name="description" content="Research publication on human-AI interaction patterns in conversational interfaces."/><meta name="author" content="Ali Tayyebi"/><meta name="keywords" content="AI design,product design,LLM,Meta,design leadership,enterprise design"/><meta property="og:title" content="Ali Tayyebi — Design Lead Manager"/><meta property="og:description" content="Director of AI-Driven Product Design at Meta Superintelligence Labs"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Ali Tayyebi — Design Lead Manager"/><meta name="twitter:description" content="Director of AI-Driven Product Design at Meta Superintelligence Labs"/><link rel="icon" href="/26porto/favicon.ico?favicon.0b3bf435.ico" sizes="256x256" type="image/x-icon"/><script src="/26porto/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="antialiased"><div hidden=""><!--$--><!--/$--></div><header class="fixed top-0 left-0 right-0 z-50 bg-[var(--background)]/90 backdrop-blur-sm border-b border-[var(--border)]"><nav class="max-w-4xl mx-auto px-6 py-4 flex items-center justify-between"><a class="font-medium text-sm tracking-tight" href="/26porto/">Ali Tayyebi</a><ul class="flex items-center gap-8"><li><a class="text-sm transition-colors text-[var(--muted)] hover:text-[var(--foreground)]" href="/26porto/">Home</a></li><li><a class="text-sm transition-colors text-[var(--muted)] hover:text-[var(--foreground)]" href="/26porto/work/">Work</a></li><li><a class="text-sm transition-colors text-[var(--foreground)]" href="/26porto/paper/">Paper</a></li><li><a class="text-sm transition-colors text-[var(--muted)] hover:text-[var(--foreground)]" href="/26porto/about/">About</a></li><li><a class="text-sm transition-colors text-[var(--muted)] hover:text-[var(--foreground)]" href="/26porto/contact/">Contact</a></li></ul></nav></header><main class="pt-16 min-h-screen"><div class="max-w-4xl mx-auto px-6 py-24"><header class="mb-16"><h1 class="text-[2.75rem] font-medium tracking-tight mb-4">Research</h1><p class="text-lg text-[var(--muted)] max-w-xl">Academic contributions to the field of human-AI interaction design.</p></header><article class="border-t border-[var(--border)] pt-12"><div class="mb-8"><div class="flex items-center gap-3 mb-4"><span class="text-xs text-[var(--muted)] border border-[var(--border)] px-2 py-0.5 rounded">CHI 2024</span><span class="text-xs text-[var(--muted)]">Co-author</span></div><h2 class="text-2xl font-medium tracking-tight mb-3">Design Patterns for Trust Calibration in LLM-Based Conversational Interfaces</h2><p class="text-sm text-[var(--muted)] mb-6">Published in Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems</p></div><section class="mb-12"><h3 class="text-sm font-medium uppercase tracking-wide text-[var(--muted)] mb-4">Problem</h3><p class="text-[var(--muted)]">As large language models become integrated into consumer and enterprise products, users struggle to develop accurate mental models of AI capabilities. This leads to two failure modes: over-trust (accepting incorrect outputs uncritically) and under-trust (failing to use AI for tasks where it excels). The research investigates design interventions that help users calibrate their trust appropriately based on task type, model confidence, and output verifiability.</p></section><section class="mb-12"><h3 class="text-sm font-medium uppercase tracking-wide text-[var(--muted)] mb-4">Contribution</h3><p class="text-[var(--muted)] mb-4">My contribution focused on the design and implementation of interface prototypes used in the study. Working with research partners, I developed a framework of trust calibration patterns that were tested with participants across different experience levels and task domains.</p><p class="text-[var(--muted)]">Key design patterns identified include: explicit uncertainty indicators, source attribution hierarchies, comparative response generation, and progressive verification flows. The paper presents empirical evidence for which patterns are most effective in different contexts.</p></section><section class="mb-12"><h3 class="text-sm font-medium uppercase tracking-wide text-[var(--muted)] mb-4">Outcomes</h3><ul class="text-[var(--muted)] list-disc pl-5 space-y-2"><li>The paper was accepted at CHI 2024, the premier venue for human-computer interaction research</li><li>Findings have been integrated into design guidelines at Meta and influenced industry practices</li><li>The trust calibration framework is being extended in follow-up research</li></ul></section><section class="bg-neutral-50 p-6 rounded-lg"><h3 class="text-sm font-medium uppercase tracking-wide text-[var(--muted)] mb-4">Citation</h3><p class="text-sm text-[var(--muted)] font-mono">Chen, L., Tayyebi, A., Ramirez, S., &amp; Wong, K. (2024). Design Patterns for Trust Calibration in LLM-Based Conversational Interfaces. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI &#x27;24). ACM, New York, NY, USA.</p></section></article><nav class="pt-12 border-t border-[var(--border)] mt-16"><a class="text-sm text-[var(--muted)] hover:text-[var(--foreground)] transition-colors" href="/26porto/about/">Learn more about my background →</a></nav></div><!--$--><!--/$--></main><footer class="border-t border-[var(--border)] mt-24"><div class="max-w-4xl mx-auto px-6 py-8 flex items-center justify-between text-sm text-[var(--muted)]"><span>© <!-- -->2025<!-- --> Ali Tayyebi</span><div class="flex items-center gap-6"><a href="https://linkedin.com" target="_blank" rel="noopener noreferrer" class="hover:text-[var(--foreground)] transition-colors">LinkedIn</a></div></div></footer><script src="/26porto/_next/static/chunks/ee072962c21fa1dd.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[88589,[\"/26porto/_next/static/chunks/5fcf6768c2e01b0d.js\"],\"default\"]\n3:I[39756,[\"/26porto/_next/static/chunks/ff1a16fafef87110.js\",\"/26porto/_next/static/chunks/7340adf74ff47ec0.js\"],\"default\"]\n4:I[37457,[\"/26porto/_next/static/chunks/ff1a16fafef87110.js\",\"/26porto/_next/static/chunks/7340adf74ff47ec0.js\"],\"default\"]\nb:I[68027,[],\"default\"]\n:HL[\"/26porto/_next/static/chunks/91d2d8100e5e5b96.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"wJmNvrHaXSuk-OdWqoO31\",\"c\":[\"\",\"paper\",\"\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"paper\",{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/26porto/_next/static/chunks/91d2d8100e5e5b96.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/26porto/_next/static/chunks/5fcf6768c2e01b0d.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"antialiased\",\"children\":[[\"$\",\"$L2\",null,{}],[\"$\",\"main\",null,{\"className\":\"pt-16 min-h-screen\",\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"footer\",null,{\"className\":\"border-t border-[var(--border)] mt-24\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-4xl mx-auto px-6 py-8 flex items-center justify-between text-sm text-[var(--muted)]\",\"children\":[[\"$\",\"span\",null,{\"children\":[\"© \",2025,\" Ali Tayyebi\"]}],[\"$\",\"div\",null,{\"className\":\"flex items-center gap-6\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://linkedin.com\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"hover:text-[var(--foreground)] transition-colors\",\"children\":\"LinkedIn\"}]}]]}]}]]}]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"div\",null,{\"className\":\"max-w-4xl mx-auto px-6 py-24\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-16\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-[2.75rem] font-medium tracking-tight mb-4\",\"children\":\"Research\"}],[\"$\",\"p\",null,{\"className\":\"text-lg text-[var(--muted)] max-w-xl\",\"children\":\"Academic contributions to the field of human-AI interaction design.\"}]]}],[\"$\",\"article\",null,{\"className\":\"border-t border-[var(--border)] pt-12\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center gap-3 mb-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-xs text-[var(--muted)] border border-[var(--border)] px-2 py-0.5 rounded\",\"children\":\"CHI 2024\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-[var(--muted)]\",\"children\":\"Co-author\"}]]}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-medium tracking-tight mb-3\",\"children\":\"Design Patterns for Trust Calibration in LLM-Based Conversational Interfaces\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-[var(--muted)] mb-6\",\"children\":\"Published in Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems\"}]]}],[\"$\",\"section\",null,{\"className\":\"mb-12\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-sm font-medium uppercase tracking-wide text-[var(--muted)] mb-4\",\"children\":\"Problem\"}],[\"$\",\"p\",null,{\"className\":\"text-[var(--muted)]\",\"children\":\"As large language models become integrated into consumer and enterprise products, users struggle to develop accurate mental models of AI capabilities. This leads to two failure modes: over-trust (accepting incorrect outputs uncritically) and under-trust (failing to use AI for tasks where it excels). The research investigates design interventions that help users calibrate their trust appropriately based on task type, model confidence, and output verifiability.\"}]]}],\"$L5\",\"$L6\",\"$L7\"]}],\"$L8\"]}],null,\"$L9\"]}],{},null,false,false]},null,false,false]},null,false,false],\"$La\",false]],\"m\":\"$undefined\",\"G\":[\"$b\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"c:I[22016,[\"/26porto/_next/static/chunks/5fcf6768c2e01b0d.js\"],\"\"]\nd:I[97367,[\"/26porto/_next/static/chunks/ff1a16fafef87110.js\",\"/26porto/_next/static/chunks/7340adf74ff47ec0.js\"],\"OutletBoundary\"]\ne:\"$Sreact.suspense\"\n10:I[97367,[\"/26porto/_next/static/chunks/ff1a16fafef87110.js\",\"/26porto/_next/static/chunks/7340adf74ff47ec0.js\"],\"ViewportBoundary\"]\n12:I[97367,[\"/26porto/_next/static/chunks/ff1a16fafef87110.js\",\"/26porto/_next/static/chunks/7340adf74ff47ec0.js\"],\"MetadataBoundary\"]\n5:[\"$\",\"section\",null,{\"className\":\"mb-12\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-sm font-medium uppercase tracking-wide text-[var(--muted)] mb-4\",\"children\":\"Contribution\"}],[\"$\",\"p\",null,{\"className\":\"text-[var(--muted)] mb-4\",\"children\":\"My contribution focused on the design and implementation of interface prototypes used in the study. Working with research partners, I developed a framework of trust calibration patterns that were tested with participants across different experience levels and task domains.\"}],[\"$\",\"p\",null,{\"className\":\"text-[var(--muted)]\",\"children\":\"Key design patterns identified include: explicit uncertainty indicators, source attribution hierarchies, comparative response generation, and progressive verification flows. The paper presents empirical evidence for which patterns are most effective in different contexts.\"}]]}]\n6:[\"$\",\"section\",null,{\"className\":\"mb-12\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-sm font-medium uppercase tracking-wide text-[var(--muted)] mb-4\",\"children\":\"Outcomes\"}],[\"$\",\"ul\",null,{\"className\":\"text-[var(--muted)] list-disc pl-5 space-y-2\",\"children\":[[\"$\",\"li\",null,{\"children\":\"The paper was accepted at CHI 2024, the premier venue for human-computer interaction research\"}],[\"$\",\"li\",null,{\"children\":\"Findings have been integrated into design guidelines at Meta and influenced industry practices\"}],[\"$\",\"li\",null,{\"children\":\"The trust calibration framework is being extended in follow-up research\"}]]}]]}]\n7:[\"$\",\"section\",null,{\"className\":\"bg-neutral-50 p-6 rounded-lg\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-sm font-medium uppercase tracking-wide text-[var(--muted)] mb-4\",\"children\":\"Citation\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-[var(--muted)] font-mono\",\"children\":\"Chen, L., Tayyebi, A., Ramirez, S., \u0026 Wong, K. (2024). Design Patterns for Trust Calibration in LLM-Based Conversational Interfaces. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI '24). ACM, New York, NY, USA.\"}]]}]\n8:[\"$\",\"nav\",null,{\"className\":\"pt-12 border-t border-[var(--border)] mt-16\",\"children\":[\"$\",\"$Lc\",null,{\"href\":\"/about\",\"className\":\"text-sm text-[var(--muted)] hover:text-[var(--foreground)] transition-colors\",\"children\":\"Learn more about my background →\"}]}]\n9:[\"$\",\"$Ld\",null,{\"children\":[\"$\",\"$e\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@f\"}]}]\na:[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L10\",null,{\"children\":\"$L11\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$L12\",null,{\"children\":[\"$\",\"$e\",null,{\"name\":\"Next.Metadata\",\"children\":\"$L13\"}]}]}],null]}]\n"])</script><script>self.__next_f.push([1,"11:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"14:I[27201,[\"/26porto/_next/static/chunks/ff1a16fafef87110.js\",\"/26porto/_next/static/chunks/7340adf74ff47ec0.js\"],\"IconMark\"]\nf:null\n13:[[\"$\",\"title\",\"0\",{\"children\":\"Research — Ali Tayyebi\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Research publication on human-AI interaction patterns in conversational interfaces.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"author\",\"content\":\"Ali Tayyebi\"}],[\"$\",\"meta\",\"3\",{\"name\":\"keywords\",\"content\":\"AI design,product design,LLM,Meta,design leadership,enterprise design\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:title\",\"content\":\"Ali Tayyebi — Design Lead Manager\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:description\",\"content\":\"Director of AI-Driven Product Design at Meta Superintelligence Labs\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"7\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"8\",{\"name\":\"twitter:title\",\"content\":\"Ali Tayyebi — Design Lead Manager\"}],[\"$\",\"meta\",\"9\",{\"name\":\"twitter:description\",\"content\":\"Director of AI-Driven Product Design at Meta Superintelligence Labs\"}],[\"$\",\"link\",\"10\",{\"rel\":\"icon\",\"href\":\"/26porto/favicon.ico?favicon.0b3bf435.ico\",\"sizes\":\"256x256\",\"type\":\"image/x-icon\"}],[\"$\",\"$L14\",\"11\",{}]]\n"])</script></body></html>